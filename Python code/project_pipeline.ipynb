{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57417759-6545-4f97-8844-873e35c340c8",
   "metadata": {},
   "source": [
    "# Full pipeline\n",
    "\n",
    "1. Trailmap <br/>\n",
    "    1.1 Training <br/>\n",
    "    1.2 Output <br/>\n",
    "2. Skeletons <br/>\n",
    "    2.1 Skeletonize_3d <br/>\n",
    "    2.2 Removal of small, disconnected objects\n",
    "3. Corrections and Atlas alignment\n",
    "4. Plots and Results\n",
    "5. Appendix\n",
    "\n",
    "---\n",
    "### Mice:\n",
    "Mesospim data: <br/>\n",
    "Al207\n",
    "Al209\n",
    "Al215\n",
    "Al211\n",
    "Al210\n",
    "Al213\n",
    "Al246\n",
    "Al249\n",
    "\n",
    "---\n",
    "### Packages:\n",
    "It is best to create two separate environments. <br/> \n",
    "1. Training and segmentation (tensorflow)\n",
    "2. Data analysis, Elastix, image processing, cython, else...\n",
    "\n",
    "#### Env1:\n",
    "**Version 1** (default, not recommended): <br/>\n",
    "> conda create -n trailmap_env tensorflow-gpu=2.1 opencv=3.4.2 pillow=7.0.0 python=3.7 <br/>\n",
    "\n",
    "(Installs automatically cuda-toolkit, cudnn from anaconda for env only)\n",
    "\n",
    "**Version 2** (recommended): <br/>\n",
    "> conda create -n trailmap_env python=3.9 <br/>\n",
    "> conda activate trailmap_env <br/>\n",
    "> pip install tensorflow <br/>\n",
    "> pip install pillow <br/>\n",
    "> pip install opencv-python <br/>\n",
    "\n",
    "**You need to install** latest nvidia-driver for the gfx card, cuda-toolkit and cudnn from nvidia website. **/!\\ guidelines** ! <br/>\n",
    "To keep in mind: \n",
    "- cuda-toolkit needs to be compatible with the gfx card. cudnn needs to be compatible with cuda-toolkit.\n",
    "- Tensorflow version has to be compatible with cuda-toolkit, cudnn and python-version.\n",
    "- For the RTX3090, cudnn should be in version 8.1+ if possible (because of hardware architecture), otherwise you will get some substantial loss in performance. \n",
    "- Tensorflow is recommended to be at least in version 2.4 for RTX 30 series GPUs.\n",
    "- pip installed *tensorflow=2.8*. Need to check if all packages are compatible but should be good. (Use standard checks: gpu hardware detection, ...)\n",
    "- pip is not monitored by anaconda (no check for compatibility and no logs in env versions)\n",
    "\n",
    "#### Env2:\n",
    "> conda create -n data_analysis python=3.9\n",
    "\n",
    "- Would not mess with python=3.10 at the moment.\n",
    "- Would recommend to use *mamba* to install some of the packages (faster and less annoying than conda). Has to be installed in (base) environment. \n",
    "> conda deactivate <br/>\n",
    "> conda install -c conda-forge mamba <br/>\n",
    "> conda activate data_analysis <br/>\n",
    "> mamba install tqdm scikit-image ... <br/>\n",
    "> pip install matplotlib <br/>\n",
    "> pip install SimpleITK <br/>\n",
    "- Addionnal package: tqdm, matplotlib, SimpleITK, skimage, plotly, dask-image, cython, (+whatever else you need)\n",
    "- You can use **conda list** (or **mamba list**) on terminal to get version of all installed packages within environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96fbb7d-9d34-472b-9d77-31b1f6194491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data_analysis env\n",
    "\n",
    "import os\n",
    "import tkinter.filedialog as fdialog #window to select directories\n",
    "from tqdm import tqdm #progress bars\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "#import anne_code.Neuron_analysis as na #custum functions\n",
    "#from anne_code.Neuron_analysis import *\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SimpleITK as sitk #elastix\n",
    "#import skimage\n",
    "from skimage import io, morphology, measure\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "import plotly.graph_objects as go\n",
    "import cc3d\n",
    "\n",
    "from project_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017851e4-7779-4b69-a1c9-87e6071a3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ddbfd-7480-4610-919b-8efc16d25a79",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Trailmap\n",
    "\n",
    "See Trailmap README on how to train and use the current weights of the model to get the probabilitic maps. <br/>\n",
    "Below some utility function: the images have to be within the same folder. Might want to extract a list of images from a .tiff stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0a01ca-2ccc-4ae0-ab15-8ec5dde63632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected mice: /data/Lucas/AL210/AL210_rLS.tif\n",
      "Folder name to copy: \n",
      "\t /data/Lucas/AL210/Al210_1\n"
     ]
    }
   ],
   "source": [
    "image_stack = fdialog.askopenfilename(title='Please select tiff stack')\n",
    "output_folder = fdialog.askdirectory(title='Please select the output directory')\n",
    "#mice_names = ['AL207','AL209','AL215','AL211','AL210','AL213','AL246','AL249']\n",
    "#data_folder_lsens = '/home/lucasdelez/Documents/lsens_server/data/' #data en mounted lsens access drive\n",
    "#image_stack = data_folder_lsens + mice_names[0]\n",
    "#output_folder = '/home/lucasdelez/Documents/segmented_images/Al207_1'\n",
    "\n",
    "print(\"Selected mice:\", image_stack)\n",
    "print(\"Folder name to copy:\",'\\n\\t',output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "209e8e8f-4cc3-44f2-a7bc-eb9db2cc3cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack dimensions: (1359, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Convert image stack to folder containing individual images.\n",
    "image_stack = r'/data/Lucas/AL215/AL215_rLS.tif'\n",
    "output_folder = r'/data/Lucas/AL215/Al215_1'\n",
    "mice_name = r'AL215_rLS'\n",
    "from_stack_to_folder(image_stack, output_folder, mice_name, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efa15e9d-08f0-4c74-9673-85ea799bf706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack dimensions: (1457, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Convert image stack to folder containing individual images.\n",
    "image_stack = r'/data/Lucas/AL207/AL207_rLS.tif'\n",
    "output_folder = r'/data/Lucas/AL207/AL207_1'\n",
    "mice_name = r'AL207_rLS'\n",
    "from_stack_to_folder(image_stack, output_folder, mice_name, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d9699e-0052-4273-ae90-f39041319bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack dimensions: (1381, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Convert image stack to folder containing individual images.\n",
    "image_stack = r'/data/Lucas/AL210/AL210_rLS.tif'\n",
    "output_folder = r'/data/Lucas/AL210/AL210_1'\n",
    "mouse_name = r'AL210_rLS'\n",
    "from_stack_to_folder(image_stack, output_folder, mouse_name, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2859bbb6-bdbb-4b8f-bf0d-e02ec6caffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack dimensions: (1500, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Convert image stack to folder containing individual images.\n",
    "image_stack = r'/data/Lucas/AL246/AL246_rLS.tif'\n",
    "output_folder = r'/data/Lucas/AL246/AL246_1'\n",
    "mouse_name = r'AL246_rLS'\n",
    "from_stack_to_folder(image_stack, output_folder, mouse_name, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46cafd5-66ca-4840-8752-7da9b62cf0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Lucas/AL249/AL249_1 already exists. Will be overwritten.\n",
      "Stack dimensions: (1500, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "image_stack = r'/data/Lucas/AL249/AL249_rLS.tiff'\n",
    "output_folder = r'/data/Lucas/AL249/AL249_1'\n",
    "mouse_name = r'AL249_rLS'\n",
    "from_stack_to_folder(image_stack, output_folder, mouse_name, '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e3a10-7567-4701-ae12-0bc808cb2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stack = r'/data/Lucas/AL257/AL257_561_rLS.tiff'\n",
    "output_folder = r'/data/Lucas/AL257/AL257_1'\n",
    "mouse_name = r'AL257_561_rLS'\n",
    "from_stack_to_folder(image_stack, output_folder, mouse_name, '.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589416d1-b45f-4ccd-b51b-56ec0ecd2f60",
   "metadata": {},
   "source": [
    "**Below is deprecated**, you should run the functions from a terminal window. \n",
    "\n",
    "- Check batch size, loaded weights, input/output folders before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b6a9d8-09bb-46be-b673-0a4c2a5caa1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 09:55:53.420332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.86GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-03-21 09:55:53.420481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-21 09:55:53.420504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-21 09:55:53.420524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-21 09:55:53.420543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-21 09:55:53.420562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-21 09:55:53.420581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-21 09:55:53.420601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-21 09:55:53.422525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-03-21 09:55:53.424029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.86GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-03-21 09:55:53.424118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-21 09:55:53.424139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-21 09:55:53.424159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-21 09:55:53.424178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-21 09:55:53.424197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-21 09:55:53.424215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-21 09:55:53.424234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-21 09:55:53.426323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2022-03-21 09:55:53.426360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-21 09:55:53.426367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2022-03-21 09:55:53.426373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2022-03-21 09:55:53.428547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22523 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucasdelez/Documents/segmented_images/seg-Al207_1 already exists. Will be overwritten\n",
      "Name: Al207_1\n",
      "[                                        ]   0%       ETA: Pending        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 10:00:42.223684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-21 10:15:04.800179: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n",
      "Relying on driver to perform ptx compilation. This message will be only logged once.\n",
      "2022-03-21 10:15:04.911760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%       Total: 46.6 mins    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run trailmap: terminal command, specify: 1)script file, 2) input folder\n",
    "# Performance depends on batch size\n",
    "%run /home/lucasdelez/Documents/TRAILMAP/segment_brain_batch.py /home/lucasdelez/Documents/segmented_images/Al207_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003526c3-351f-409b-839d-e453fd5db356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To process labels\n",
    "%run TRAILMAP-master/prepare_data.py \"process_labels\" E:/Lucas/Training data/Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895213a5-15b3-4f21-80b0-64fd8a3c49a9",
   "metadata": {},
   "source": [
    "e workstations were operated by Linux Ubunt## 2. Skeletons \n",
    "\n",
    "### 2.1 Skeletonize_3d\n",
    "Utilizes the trailmap output images from Trailmap in order to get a skeletonized stack. <br/>\n",
    "The skeleton algorithm should work better with high z resolution. <br/><br/>\n",
    "I tried to follow the algorithm presented in TRAILMAP paper. It uses 8 different thresholds to \"segmentate/cut\" pixels in function of their probability to be an axon. <br/> and The skeletonize_3d function from skimage.morphology is then used in order to get the skeletons of the axons. Finally, all resulting skeleton images are summed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fed23e-bac3-4196-bf50-2691f489e3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton for threshold 0.2 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_0 directory created !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.30000000000000004 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_1 directory created !\n",
      "Images for threshold 0.30000000000000004 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_2 directory created !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6000000000000001 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6000000000000001 saved !\n",
      "Skeleton for threshold 0.7000000000000001 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7000000000000001 saved !\n",
      "Skeleton for threshold 0.8 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_6 directory created !\n",
      "Images for threshold 0.8 saved !\n",
      "Skeleton for threshold 0.9 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_7 directory created !\n",
      "Images for threshold 0.9 saved !\n",
      "/data/Lucas/AL207/skel-seg-Al207_dense/weighted_sum_skeleton directory created !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_0',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_1',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_2',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_3',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_4',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_5',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_6',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_dense/skel_thresh_7']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeletons_3d(r'/data/Lucas/AL207/seg-Al207_dense', r\"/data/Lucas/AL207\")\n",
    "#img_stack = skeleton_3d('/home/lucasdelez/Documents/segmented_images/seg-Al207_substack/*.tif', output_folder, True)\n",
    "#img_stack = skeleton_3d(file_names, output_folder, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6492c562-f475-46b8-bf1f-5da2bbd8b9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton for threshold 0.2 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_0 directory created !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.30000000000000004 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_1 directory created !\n",
      "Images for threshold 0.30000000000000004 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_2 directory created !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6000000000000001 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6000000000000001 saved !\n",
      "Skeleton for threshold 0.7000000000000001 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7000000000000001 saved !\n",
      "Skeleton for threshold 0.8 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_6 directory created !\n",
      "Images for threshold 0.8 saved !\n",
      "Skeleton for threshold 0.9 computed !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/skel_thresh_7 directory created !\n",
      "Images for threshold 0.9 saved !\n",
      "/data/Lucas/AL211/skel-seg-AL211_20220506_2/weighted_sum_skeleton directory created !\n",
      "Skeleton for threshold 0.2 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_0 directory created !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.30000000000000004 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_1 directory created !\n",
      "Images for threshold 0.30000000000000004 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_2 directory created !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6000000000000001 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6000000000000001 saved !\n",
      "Skeleton for threshold 0.7000000000000001 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7000000000000001 saved !\n",
      "Skeleton for threshold 0.8 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_6 directory created !\n",
      "Images for threshold 0.8 saved !\n",
      "Skeleton for threshold 0.9 computed !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/skel_thresh_7 directory created !\n",
      "Images for threshold 0.9 saved !\n",
      "/data/Lucas/AL213/skel-seg-AL213_20220506_2/weighted_sum_skeleton directory created !\n",
      "Skeleton for threshold 0.2 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_0 directory created !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.30000000000000004 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_1 directory created !\n",
      "Images for threshold 0.30000000000000004 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_2 directory created !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6000000000000001 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6000000000000001 saved !\n",
      "Skeleton for threshold 0.7000000000000001 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7000000000000001 saved !\n",
      "Skeleton for threshold 0.8 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_6 directory created !\n",
      "Images for threshold 0.8 saved !\n",
      "Skeleton for threshold 0.9 computed !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/skel_thresh_7 directory created !\n",
      "Images for threshold 0.9 saved !\n",
      "/data/Lucas/AL209/skel-seg-AL209_20220506_2/weighted_sum_skeleton directory created !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/Lucas/AL209/skel-seg-AL209_20220506_2/weighted_sum_skeleton'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeletons_3d(r'/data/Lucas/AL211/seg-AL211_20220506_2', r'/data/Lucas/AL211')\n",
    "skeletons_3d(r'/data/Lucas/AL213/seg-AL213_20220506_2', r'/data/Lucas/AL213')\n",
    "skeletons_3d(r'/data/Lucas/AL209/seg-AL209_20220506_2', r'/data/Lucas/AL209')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e97816f-18e5-4af8-b31f-675cae4b6ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton for threshold 0.2 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_0 directory created !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.3 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_1 directory created !\n",
      "Images for threshold 0.3 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_2 directory created !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6 saved !\n",
      "Skeleton for threshold 0.7 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7 saved !\n",
      "Skeleton for threshold 0.8 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_6 directory created !\n",
      "Images for threshold 0.8 saved !\n",
      "Skeleton for threshold 0.9 computed !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/skel_thresh_7 directory created !\n",
      "Images for threshold 0.9 saved !\n",
      "/data/Lucas/AL246/skel-seg-AL246_20220506_2/weighted_sum_skeleton directory created !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/Lucas/AL246/skel-seg-AL246_20220506_2/weighted_sum_skeleton'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeletons_3d_bis(r'/data/Lucas/AL246/seg-AL246_20220506_2', r'/data/Lucas/AL246')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28570f0c-7449-4d39-8e03-d467e9ea4139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton for threshold 0.2 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_0 directory created !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.3 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_1 directory created !\n",
      "Images for threshold 0.3 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_2 directory created !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6 saved !\n",
      "Skeleton for threshold 0.7 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7 saved !\n",
      "Skeleton for threshold 0.8 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_6 directory created !\n",
      "Images for threshold 0.8 saved !\n",
      "Skeleton for threshold 0.9 computed !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/skel_thresh_7 directory created !\n",
      "Images for threshold 0.9 saved !\n",
      "/data/Lucas/AL207/skel-seg-AL207_dense/weighted_sum_skeleton directory created !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/Lucas/AL207/skel-seg-AL207_dense/weighted_sum_skeleton'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeletons_3d_bis(r'/data/Lucas/AL207/seg-AL207_dense', r'/data/Lucas/AL207')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ab5d8-ad6b-4665-868a-72ca68cdb98b",
   "metadata": {},
   "source": [
    "### 2.2. Removal of small objects\n",
    "\n",
    "If skeletonize_3d works accordingly. It should be possible to measure the length in 3d of the objects.\n",
    "\n",
    "Two steps proposed: \n",
    "    1. Based on size of labelled objects. \n",
    "    2. Based on avg probability of the axon.\n",
    "    \n",
    "Two thresholds required. \n",
    "\n",
    "Looking at the probability distribution of the axons. Can't really be done at this stage. \n",
    "It is necessary to consider what is happening in later stages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a0f986-abfb-4f8d-a57a-425c9b742f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2196ed37-8544-4c8f-abc9-3cfbc5b1d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "def compute_sum(np.ndarray[float, ndim=3] vol, np.ndarray[long long, ndim=2] list_coords):\n",
    "    cdef double sum_proba = 0.0\n",
    "    cdef int i = 0\n",
    "    for i in range(len(list_coords)):\n",
    "        sum_proba += vol[list_coords[i][0],list_coords[i][1],list_coords[i][2]]\n",
    "    \n",
    "    return sum_proba/len(list_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ebd7e8-1a00-45d7-897c-a81eab5310c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_skel_probas(stack):\n",
    "    # Look at the probability distributions of data within the stacks\n",
    "    # Compute the means but should look into the distribution\n",
    "    \n",
    "    label_stack = np.copy(stack) # forces a copy\n",
    "    if len(label_stack[label_stack < 0]) > 0:\n",
    "        print('Error: values below 0 detected within the .tif stack')\n",
    "        print('Stack exited with no change')\n",
    "        return stack\n",
    "    label_stack[label_stack > 0] = 1\n",
    "    label_stack = measure.label(label_stack, background=0)\n",
    "    print('In stack: individual \"blobs\":', np.max(label_stack)) #Sanity check\n",
    "    \n",
    "    propsa = measure.regionprops(label_stack)\n",
    "    probablity_densities = []\n",
    "    for count, item in enumerate(propsa):\n",
    "        probablity_densities.append(compute_sum(stack, item.coords))\n",
    "                \n",
    "    return probablity_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c440983-47e1-4052-a1e7-49fc32835fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: individual \"blobs\": 108936\n",
      "Blobs that are removed: 108664\n"
     ]
    }
   ],
   "source": [
    "stack = from_folder_to_stack(r'/data/Lucas/AL207/skel-seg-Al207_dense/weighted_sum_skeleton')\n",
    "stack = trim_small_elements(stack, 1000, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24075bd-e639-496e-b120-c40f5e263aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_densities = compute_skel_probas(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2dbd30a-9113-451e-9764-63df3ed2dc4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1905657812054988, 0.975129300655756, 1.2805225802076685, 0.9739292485420931, 0.9993464176923065, 1.2093767674701525, 0.6472422122883854, 0.8386904836055779, 0.7927576704443663, 0.8079825921094989, 0.6864784620979034, 0.8591528070270564, 0.7835987367352862, 1.33976111250831, 1.1195369158290576, 0.8437801437271021, 1.2527542506676104, 1.4052197980479553, 0.9171854530754266, 0.9445876361821423, 1.3154135515871352, 0.6996800069570541, 1.1405154767263797, 1.0583650301362852, 0.9410635257797368, 0.6992366504464441, 0.6792869358141678, 0.9332988720229272, 0.7236972774561522, 0.8760330678510272, 1.1017361222421405, 1.1278180084128662, 0.683361928724711, 1.0763135371949526, 1.1591800476778, 0.8703508872996297, 0.8353139106267771, 1.0493372723745493, 0.6157963517129266, 0.8080173425723517, 1.0163461653133616, 0.9220149345807175, 1.1020512914619385, 1.2937390437472835, 1.0782758759270454, 1.122657653367685, 0.8668402884052031, 0.7156051046387025, 1.3845454694466157, 1.015587108908161, 0.7126562564400956, 1.1184231829458633, 0.8629893324606359, 0.7143312191191246, 1.4934579587115027, 1.1362280818454007, 0.6796504443281153, 0.9270702549333507, 0.8916981254358711, 1.1209829993024891, 1.0744849578042037, 0.8633914507228864, 0.9669026632488301, 1.3275000146661813, 1.0291353503340168, 0.9581597344949841, 1.4573089908375296, 0.912404100370148, 0.9393250665311985, 0.891206906067914, 0.842857155416693, 1.3310391518228288, 0.7101083101186941, 1.0598651049108971, 0.9696028607455509, 1.0159400693605316, 1.533623712818797, 0.8039622703532003, 0.7387043283478762, 0.950143278456349, 1.0839161011097314, 1.3543278268687633, 0.813736270799305, 0.8207939606871181, 0.9589428048713063, 0.7754224355457016, 1.4190812900820384, 0.7412044461196652, 1.317876255243584, 0.6161616249919339, 1.2717451678583827, 1.0559543333036088, 1.3603921708133486, 0.9806613302033745, 1.371754403543054, 1.0538975619659126, 0.6907713568407642, 0.8009544112270229, 1.3723765533923367, 0.7561403591144218, 0.7569707476256636, 0.6947817912703447, 0.5500000074210734, 0.6843546344916854, 0.9276892562430218, 1.3639889358648634, 0.9115036305013127, 0.7322761303286499, 0.6992805822688286, 1.2159509335345529, 1.3366300508434519, 0.91660340088277, 0.798769583321391, 1.1157515856243603, 0.6816023806612994, 1.2390351007033509, 1.1427135803741426, 1.3538726470761784, 1.109706784599471, 0.6743682373839596, 1.3340813655923494, 0.7391975395105503, 1.1046742315670586, 0.762554306423633, 1.1405263316866598, 1.1362227046464513, 0.9078115404705343, 0.8750455468241635, 0.8776898819811737, 0.7213036648940965, 0.9587030780244199, 1.0163606126887572, 0.891815866472776, 0.8715702569928051, 0.6490530392267939, 1.528237645679181, 0.7978151376507864, 1.4093123396650427, 1.2730568934974016, 1.4815305149562066, 0.7409024829427228, 0.8120000121670384, 0.740425541132285, 1.4024822859899373, 1.396781372739525, 1.409261956358094, 1.4552906293716232, 1.3829545651026296, 0.9832840365462402, 0.7315978529048779, 1.6295228818538885, 1.278303439232109, 1.452816922375014, 1.0626099835261922, 1.271262717999637, 1.3539424447228523, 1.5526315971855285, 0.9031722159364072, 1.5768354633940926, 0.6223735492459067, 1.1890987273577456, 1.2865501163325699, 1.423391237154801, 1.0832679877483766, 1.1165225875137175, 1.1387886738347024, 1.0207516464581288, 1.0146077664130653, 1.1561776193067375, 1.3309523962041576, 0.8955555655062198, 0.9807116235240122, 1.1622093144197796]\n"
     ]
    }
   ],
   "source": [
    "print(probability_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acad94f4-bf19-484e-9f14-254b1c3c6133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5213592262233345 3.9329843725521525\n"
     ]
    }
   ],
   "source": [
    "print(np.min(probability_densities), np.max(probability_densities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b03e4f-89d1-4004-97e9-e1d0142a5b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack dimensions: (1457, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "from_vol_to_folder(stack, r'weighted_skeleton.tif', r'/data/Lucas/AL207')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1347656-756e-4c66-b9c5-dfcf3d2e3124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_0', '/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_1', '/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_2', '/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_3', '/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_4', '/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_5', '/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_6', '/data/Lucas/AL215/skel-seg-AL215_20220506_2/skel_thresh_7']\n"
     ]
    }
   ],
   "source": [
    "folder_list = get_dir(r'/data/Lucas/AL215/skel-seg-AL215_20220506_2')[:-1]\n",
    "print(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2f810e-c3bb-4be7-bf06-99b25e9a4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skeletons_3d_bis(r'/data/Lucas/AL215/seg-AL215_20220506_2', r\"/data/Lucas/AL215\")\n",
    "thresh_list = np.array(0.1*np.array(range(2,10,1))).astype('float32')\n",
    "weighted_sum_skeleton(folder_list, thresh_list, r'/data/Lucas/AL215/skel-seg-AL215_20220506_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "224e4887-edb2-4577-bdb4-9a4508a95283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_0', '/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_1', '/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_2', '/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_3', '/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_4', '/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_5', '/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_6', '/data/Lucas/AL210/skel-seg-AL210_20220428_4/skel_thresh_7']\n"
     ]
    }
   ],
   "source": [
    "folder_list = get_dir(r'/data/Lucas/AL210/skel-seg-AL210_20220428_4')[:-1]\n",
    "print(folder_list)\n",
    "thresh_list = 0.1*np.array(range(2,10,1))\n",
    "weighted_sum_skeleton(folder_list, thresh_list, r'/data/Lucas/AL210/skel-seg-AL210_20220428_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b38c21e2-dbbf-40a7-ab53-dc9a4617224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dba8bc5-7be0-4e54-b348-b7ec47b0ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "def set_to_zero(np.ndarray[float, ndim=3] vol, np.ndarray[long long, ndim=2] list_coords):\n",
    "    cdef int i = 0\n",
    "    for i in range(len(list_coords)):\n",
    "        vol[list_coords[i][0],list_coords[i][1],list_coords[i][2]] = 0\n",
    "    \n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b551730f-ce61-4db4-a74a-786cc3bc87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_small_elements(stack_filename, min_threshold, max_threshold=-1):\n",
    "    # Removing small elements increases the mean probability of remaining pixels. (Post-skeletonization)\n",
    "    # Small elements should be associated with lower probabilities of axon presence (artifacts, blood vessels,...)\n",
    "    # We want the \"big\" stuff\n",
    "    \n",
    "    label_stack = from_folder_to_stack(stack_filename) # loading stack a first time for connected-components labeling\n",
    "    label_stack = label_stack.view(dtype=np.float32) # forces a specific size (should be native size after segmentation) (check if worth doing)\n",
    "    label_stack[label_stack > 0] = 1 # binarization, checking below 0 should be unnecessary (if proper workflow order)\n",
    "    label_stack, N = cc3d.connected_components(label_stack, out_dtype=np.uint32, return_N=True) # better than skimage ?\n",
    "    #label_stack = measure.label(label_stack, background=0) #computationally expensive\n",
    "    print('Start: individual \"blobs\":', N)\n",
    "    \n",
    "    propsa = measure.regionprops(label_stack)\n",
    "    del label_stack #liberate memory\n",
    "    \n",
    "    index_list = []\n",
    "    for count, item in enumerate(propsa):\n",
    "        if len(item.coords) < min_threshold:\n",
    "            index_list.append(count)\n",
    "        elif max_threshold > 0 and len(item.coords) > max_threshold:\n",
    "            index_list.append(count)\n",
    "    \n",
    "    #del propsa #liberate memory\n",
    "    print('Blobs that are removed:', len(index_list))\n",
    "    \n",
    "    stack = from_folder_to_stack(stack_filename) # loading stack a second time\n",
    "    stack = stack.view(dtype=np.float32) # Need to check if it is worth doing\n",
    "    \n",
    "    for i in range(len(index_list)):\n",
    "        stack = set_to_zero(stack, propsa[index_list[i]].coords)\n",
    "    \n",
    "    print('End: individual \"blobs\" remaining', N-len(index_list))\n",
    "                \n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975d2b41-a71d-41f6-bcfe-189c306534a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual \"blobs\": 178285\n",
      "Blobs of size superior to 10000: 14\n"
     ]
    }
   ],
   "source": [
    "i_list, prop = find_biggest_elements(r'/data/Lucas/AL207/skel-seg-AL207_20220506_2/weighted_sum_skeleton', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f75fbb-4b08-4a8c-a1b3-80b47efba7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110 3652024\n",
      "5089 44222\n",
      "8335 12154\n",
      "18790 14606\n",
      "20044 49931\n",
      "23984 11978\n",
      "82169 32360\n",
      "83584 10596\n",
      "85569 32062\n",
      "99631 13818\n",
      "109569 22464\n",
      "137546 12628\n",
      "138428 14537\n",
      "158562 28891\n"
     ]
    }
   ],
   "source": [
    "print_biggest_connected_components(i_list, prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca8129b-1847-43d0-9196-0dbde5513d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: individual \"blobs\": 178285\n",
      "Blobs that are removed: 178284\n",
      "End: individual \"blobs\" remaining 1\n",
      "New directory created at: Al207_20220506_2_skel_trim_1e6\n",
      "Stack dimensions: (1457, 2048, 2048)\n",
      "Al207_20220506_2_skel_trim_1e6 already exists. Will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "stack = trim_small_elements(r'/data/Lucas/AL207/skel-seg-AL207_20220506_2/weighted_sum_skeleton', 1e6)\n",
    "from_vol_to_folder(stack, r'weighted_skeleton.tif', r'Al207_20220506_2_skel_trim_1e6')\n",
    "del stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cdf1f5d-34e5-4b9c-a57d-0974165963d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 240\n",
      "Start: individual \"blobs\": 178285\n",
      "Blobs that are removed: 178271\n",
      "End: individual \"blobs\" remaining 14\n",
      "New directory created at: Al207_20220506_2_skel_trim_1e4\n",
      "Stack dimensions: (1457, 2048, 2048)\n",
      "Al207_20220506_2_skel_trim_1e4 already exists. Will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "stack = trim_small_elements(r'/data/Lucas/AL207/skel-seg-AL207_20220506_2/weighted_sum_skeleton', 1e4)\n",
    "from_vol_to_folder(stack, r'weighted_skeleton.tif', r'Al207_20220506_2_skel_trim_1e4')\n",
    "del stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f59e36c-5931-4317-a583-8ad887a835ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual \"blobs\": 250430\n",
      "Blobs of size superior to 10000: 11\n"
     ]
    }
   ],
   "source": [
    "i_list, prop = find_biggest_elements(r'/data/Lucas/AL215/skel-seg-AL215_20220506_2/weighted_sum_skeleton', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "874d4bfa-d755-4c3f-8df8-c60e81f712eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 19632984\n",
      "3766 11522\n",
      "13631 25157\n",
      "21192 2732424\n",
      "26906 26341\n",
      "124828 12278\n",
      "156659 67780\n",
      "157238 13845\n",
      "186140 10015\n",
      "211523 12148\n",
      "215752 36056\n"
     ]
    }
   ],
   "source": [
    "print_biggest_connected_components(i_list, prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ff25da9-0d4d-4631-b53e-2cf0a491eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: individual \"blobs\": 250430\n",
      "Blobs that are removed: 250419\n",
      "End: individual \"blobs\" remaining 11\n",
      "New directory created at: Al215_20220506_2_skel_trim_1e4\n",
      "Stack dimensions: (1359, 2048, 2048)\n",
      "Al215_20220506_2_skel_trim_1e4 already exists. Will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "stack = trim_small_elements(r'/data/Lucas/AL215/skel-seg-AL215_20220506_2/weighted_sum_skeleton', 1e4)\n",
    "from_vol_to_folder(stack, r'weighted_skeleton.tif', r'Al215_20220506_2_skel_trim_1e4')\n",
    "del stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff7d4df2-98a9-4f17-887e-9ecd5715e3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: individual \"blobs\": 250430\n",
      "Blobs that are removed: 250419\n",
      "End: individual \"blobs\" remaining 11\n",
      "New directory created at: Al215_20220506_2_skel_trim_1e6\n",
      "Stack dimensions: (1359, 2048, 2048)\n",
      "Al215_20220506_2_skel_trim_1e6 already exists. Will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "stack = trim_small_elements(r'/data/Lucas/AL215/skel-seg-AL215_20220506_2/weighted_sum_skeleton', 1e4)\n",
    "from_vol_to_folder(stack, r'weighted_skeleton.tif', r'Al215_20220506_2_skel_trim_1e6')\n",
    "del stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "783758b3-dcc1-44b8-a503-e70809415237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: individual \"blobs\": 315179\n",
      "Blobs that are removed: 315175\n",
      "End: individual \"blobs\" remaining 4\n",
      "New directory created at: /data/Lucas/AL257/AL257_20220506_2_skel_trim_1e4\n",
      "Stack dimensions: (1296, 2048, 2048)\n",
      "/data/Lucas/AL257/AL257_20220506_2_skel_trim_1e4 already exists. Will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "stack = trim_small_elements(r'/data/Lucas/AL257/skel-seg-AL257_20220506_2/weighted_sum_skeleton', 1e4)\n",
    "from_vol_to_folder(stack, r'weighted_skeleton.tif', r'/data/Lucas/AL257/AL257_20220506_2_skel_trim_1e4')\n",
    "del stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dcfa033-112e-4f87-9838-e26c78d9a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: individual \"blobs\": 188572\n",
      "Blobs that are removed: 188566\n",
      "End: individual \"blobs\" remaining 6\n",
      "New directory created at: r\"/data/Lucas/AL210/AL210_20220506_2_skel_trim_1e4\n",
      "Stack dimensions: (1381, 2048, 2048)\n",
      "r\"/data/Lucas/AL210/AL210_20220506_2_skel_trim_1e4 already exists. Will be overwritten.\n"
     ]
    }
   ],
   "source": [
    "stack = trim_small_elements(r'/data/Lucas/AL210/skel-seg-AL210_20220506_2/weighted_sum_skeleton', 1e4)\n",
    "from_vol_to_folder(stack, r'weighted_skeleton.tif', r'/data/Lucas/AL210/AL210_20220506_2_skel_trim_1e4')\n",
    "del stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83744b1-0317-401d-a5db-ebe3b0557472",
   "metadata": {},
   "source": [
    "## 3. Corrections and Atlas alignment\n",
    "\n",
    "### 3.1 Reads segmentation output and create a .txt of coordinates\n",
    "\n",
    "Writes (.txt) files from segmentation results. Modified from original code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ed183d-611d-4a66-9ee5-abc51dcef3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neuron_analysis import *\n",
    "from anne_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5688c8e-3116-4b2c-adb8-8466102ce8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at /data/Lucas/Elastix/downsampled_data/AL207_fine_25um_points.txt\n"
     ]
    }
   ],
   "source": [
    "mouse = 'AL207'\n",
    "coords = return_3d_coordinates_from_seg(f'/data/Lucas/{mouse}/{mouse}_20220506_2_skel_fine_trim')\n",
    "write_atlas_file_from_segdf(coords, f'/data/Lucas/Elastix/downsampled_data', 5 , 25, f\"{mouse}_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f6d7b66-e83c-49fd-8209-8ac3cb66e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at /data/Lucas/Elastix/downsampled_data/AL210_fine_25um_points.txt\n"
     ]
    }
   ],
   "source": [
    "mouse = 'AL210'\n",
    "coords = return_3d_coordinates_from_seg(f'/data/Lucas/{mouse}/{mouse}_20220506_2_skel_fine_trim')\n",
    "write_atlas_file_from_segdf(coords, f'/data/Lucas/Elastix/downsampled_data', 5 , 25, f\"{mouse}_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a186254f-ba9f-46bf-8215-f1bf7a15be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at /data/Lucas/Elastix/downsampled_data/AL215_fine_25um_points.txt\n"
     ]
    }
   ],
   "source": [
    "mouse = 'AL215'\n",
    "coords = return_3d_coordinates_from_seg(f'/data/Lucas/{mouse}/{mouse}_20220506_2_skel_fine_trim')\n",
    "write_atlas_file_from_segdf(coords, f'/data/Lucas/Elastix/downsampled_data', 5 , 25, f\"{mouse}_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e3df06-a4d2-4869-9d75-75aaa9c98529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at /data/Lucas/Elastix/downsampled_data/AL257_fine_25um_points.txt\n"
     ]
    }
   ],
   "source": [
    "mouse = 'AL257'\n",
    "coords = return_3d_coordinates_from_seg(f'/data/Lucas/{mouse}/{mouse}_20220506_2_skel_trim_1e6')\n",
    "write_atlas_file_from_segdf(coords, f'/data/Lucas/Elastix/downsampled_data', 5 , 25, f\"{mouse}_fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16141dd-bacd-4c27-8d4e-d34f12b0efe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at /data/Lucas/Elastix/downsampled_data/AL213_fine_25um_points.txt\n"
     ]
    }
   ],
   "source": [
    "mouse = 'AL213'\n",
    "coords = return_3d_coordinates_from_seg(f'/data/Lucas/{mouse}/{mouse}_20220506_2_skel_trim_1e6')\n",
    "write_atlas_file_from_segdf(coords, f'/data/Lucas/Elastix/downsampled_data', 5 , 25, f\"{mouse}_fine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f82f481-3e59-4cce-82a5-1c47c0180c24",
   "metadata": {},
   "source": [
    "### 3.2 Elastix and Transformix to adjust atlas\n",
    "\n",
    "Atlas alignment using Elastix.\n",
    "Can be done using the terminal or by running simple Elastix\n",
    "- First part is to check the Allen template file\n",
    "- Second part is to downsample the original brain to template dimensions\n",
    "- You need to crop the stack in order to facilitate the registration\n",
    "- You can then perform registration using the downsampled autofluorescence brain as moving img and the cropped reference atlas as fixed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad0b8aa-a48f-421d-b828-ea99e607827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import block_reduce\n",
    "from datetime import datetime\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c57761e8-edef-4f0c-a16c-a95a5bb7cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_folder = r'/data/Lucas/AL211/AL211_1'\n",
    "output_folder = r'/home/lucasdelez/Documents/AllenBrainCCFv3'\n",
    "\n",
    "def downscale_imgs_allen(in_folder, out_folder, factor):\n",
    "    img_stack = dask_image.imread.imread(in_folder + \"/*.tif\").compute()\n",
    "    return ndimage.zoom(img_stack, zoom=factor)\n",
    "\n",
    "zoom_seq = (5/25,5.3/25,5.3/25)\n",
    "img_stack = downscale_imgs_allen(input_folder, output_folder, factor=zoom_seq) #Factor defined for Mesospim\n",
    "write_tiff_stack(img_stack, r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al211_25um_corrected.tif')\n",
    "\n",
    "def downscale_imgs_allen(in_folder, out_folder, factor=(5/25,5.3/25,5.3/25), output_filename):\n",
    "    img_stack = dask_image.imread.imread(in_folder + \"/*.tif\").compute()\n",
    "    img_stack = ndimage.zoom(img_stack, zoom=factor)\n",
    "    print(f'Saving downscaled stack at {output_filename}...')\n",
    "    write_tiff_stack(img_stack, output_filename)\n",
    "    print(f'Saving done !')\n",
    "    return img_stack\n",
    "\"\"\"\n",
    "\n",
    "input_folder = r'/data/Lucas/AL257/AL257_1'\n",
    "output_folder = r'/home/lucasdelez/Documents/AllenBrainCCFv3'\n",
    "\n",
    "def downscale_imgs_allen(in_folder, out_folder, factor):\n",
    "    img_stack = dask_image.imread.imread(in_folder + \"/*.tiff\").compute()\n",
    "    return block_reduce(img_stack, block_size=factor, func=np.mean)\n",
    "\n",
    "img_stack = downscale_imgs_allen(input_folder, output_folder, factor=(5,5,5)) #Factor defined for Mesospim\n",
    "write_tiff_stack(img_stack, r'/home/lucasdelez/Documents/AllenBrainCCFv3/AL257_25um.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d11d2-f37a-42e6-b0ca-945c13f7c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r'/data/Lucas/AL211/AL211_1'\n",
    "output_folder = r'/home/lucasdelez/Documents/AllenBrainCCFv3'\n",
    "\n",
    "def downscale_imgs_allen(in_folder, out_folder, factor):\n",
    "    img_stack = dask_image.imread.imread(in_folder + \"/*.tif\").compute()\n",
    "    return ndimage.zoom(img_stack, zoom=factor)\n",
    "\n",
    "zoom_seq = (5/25,5.3/25,5.3/25)\n",
    "img_stack = downscale_imgs_allen(input_folder, output_folder, factor=zoom_seq) #Factor defined for Mesospim\n",
    "write_tiff_stack(img_stack, r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al211_25um_corrected.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20398c6a-6bba-46ac-a20e-277a6d9c7cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastix done !\n"
     ]
    }
   ],
   "source": [
    "# Call registration method\n",
    "\n",
    "# To change\n",
    "output_directory = r\"/home/lucasdelez/Documents/AllenBrainCCFv3/Registration_AL211\"\n",
    "moving_img_autof = r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al211_25um_corrected.tif'\n",
    "\n",
    "\n",
    "# To keep\n",
    "fixed_img_cropped_refatlas = r\"/home/lucasdelez/Documents/AllenBrainCCFv3/template_65.tif\"\n",
    "param1 = r'/home/lucasdelez/Documents/master_project/elastix_params/clearmap_params/align_affine.txt'\n",
    "param2 = r'/home/lucasdelez/Documents/master_project/elastix_params/clearmap_params/align_bspline.txt'\n",
    "Registration(output_directory, fixed_img_cropped_refatlas, moving_img_autof, param1, param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03b194-7149-4578-be3a-af7eb339bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfx_output_directory = output_directory + r'/Transformation'\n",
    "t0_filename = output_directory + r'/TransformParameters.1.txt'\n",
    "points_directory = r'/home/lucasdelez/Documents/master_project/data/'\n",
    "\n",
    "Transformation(tempdir, fixed_img_cropped_refatlas, moving_img_autof, param1, param2, t0_filename, points_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2396e9c-28db-416c-b5a1-a37c0e3ca556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transformation(output_directory, moving_img_autof, points_filename):\n",
    "    fixed_img_cropped_refatlas = r\"/home/lucasdelez/Documents/AllenBrainCCFv3/template_65.tif\"\n",
    "    param1 = r'/home/lucasdelez/Documents/master_project/elastix_params/clearmap_params/align_affine.txt'\n",
    "    param2 = r'/home/lucasdelez/Documents/master_project/elastix_params/clearmap_params/align_bspline.txt'\n",
    "    Registration(output_directory, fixed_img_cropped_refatlas, moving_img_autof, param1, param2)\n",
    "    \n",
    "    tfx_output_directory = output_directory + r'/Transformation'\n",
    "    if not os.path.exists(tfx_output_directory):\n",
    "        os.makedirs(tfx_output_directory)\n",
    "        print(tfx_output_directory, \"directory created !\")\n",
    "    t0_filename = output_directory + r'/TransformParameters.1.txt'\n",
    "    Transformation(tfx_output_directory, fixed_img_cropped_refatlas, moving_img_autof, param1, param2, t0_filename, points_filename)\n",
    "    \n",
    "def compute_transformation_wo_registration(output_directory, moving_img_autof, points_filename):\n",
    "    fixed_img_cropped_refatlas = r\"/home/lucasdelez/Documents/AllenBrainCCFv3/template_65.tif\"\n",
    "    param1 = r'/home/lucasdelez/Documents/master_project/elastix_params/clearmap_params/align_affine.txt'\n",
    "    param2 = r'/home/lucasdelez/Documents/master_project/elastix_params/clearmap_params/align_bspline.txt'\n",
    "    \n",
    "    tfx_output_directory = output_directory + r'/Transformation'\n",
    "    if not os.path.exists(tfx_output_directory):\n",
    "        os.makedirs(tfx_output_directory)\n",
    "        print(tfx_output_directory, \"directory created !\")\n",
    "    t0_filename = output_directory + r'/TransformParameters.1.txt'\n",
    "    Transformation(tfx_output_directory, fixed_img_cropped_refatlas, moving_img_autof, param1, param2, t0_filename, points_filename)\n",
    "    \n",
    "    \n",
    "def apply_transformation(output_directory, moving_img_autof, points_filename):\n",
    "    \"\"\"\n",
    "    Not tested.\n",
    "    Assumes that all the directories exists.\n",
    "    Need to set \"InitialTransformParametersFileName\" in TransformParameters.0.txt to no \"NoInitialTransform\"\n",
    "    \"\"\"\n",
    "    tfx_output_directory = output_directory + r'/Transformation'\n",
    "    parameter_filename_0 = tfx_output_directory + r'TransformParameters.0.txt'\n",
    "    parameter_filename_1 = tfx_output_directory + r'TransformParameters.1.txt'\n",
    "    Transformation_noInverse(tfx_output_directory, points_filename, moving_img_autof, parameter_filename_0, parameter_filename_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "145d8c40-f4c1-48b6-bda6-d1b6e918ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastix done !\n",
      "/data/Lucas/Elastix/AL213/Transformation directory created !\n",
      "Transformix done !\n"
     ]
    }
   ],
   "source": [
    "#compute_transformation(r'/data/Lucas/Elastix/AL207', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al207_25um.tif', r'/home/lucasdelez/Documents/master_project/data/AL207_e4_25um_points.txt')\n",
    "#compute_transformation(r'/data/Lucas/Elastix/AL210', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al210_25um.tif', r'/home/lucasdelez/Documents/master_project/data/AL210_25um_points_1e4.txt')\n",
    "#compute_transformation_wo_registration(r'/data/Lucas/Elastix/AL207', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al207_25um.tif', r'/home/lucasdelez/Documents/master_project/data/AL207_e4_25um_points.txt')\n",
    "#compute_transformation(r'/data/Lucas/Elastix/AL210', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al210_25um.tif', r'/home/lucasdelez/Documents/master_project/data/AL210_25um_points_1e4.txt')\n",
    "#compute_transformation_wo_registration(r'/data/Lucas/Elastix/AL210', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al210_25um.tif', r'/home/lucasdelez/Documents/master_project/data/AL210_e6_25um_points.txt')\n",
    "compute_transformation(r'/data/Lucas/Elastix/AL209', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al213_25um.tif', r'/home/lucasdelez/Documents/master_project/data/AL209_e6_25um_points.txt')\n",
    "compute_transformation(r'/data/Lucas/Elastix/AL213', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al213_25um.tif', r'/home/lucasdelez/Documents/master_project/data/AL213_e6_25um_points.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def7a73-fa87-4d36-8e96-0a5bbed290cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletons_3d(r'/data/Lucas/AL211/seg-AL211_20220506_2', r'/data/Lucas/AL211')\n",
    "skeletons_3d(r'/data/Lucas/AL213/seg-AL213_20220506_2', r'/data/Lucas/AL213')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf15b7bb-369f-4365-95b0-5f8454c6425b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformix done !\n",
      "Transformix done !\n",
      "Elastix done !\n",
      "/data/Lucas/Elastix/AL215/Transformation directory created !\n",
      "Transformix done !\n"
     ]
    }
   ],
   "source": [
    "compute_transformation_wo_registration(r'/data/Lucas/Elastix/AL207', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al207_25um.tif', r'/data/Lucas/Elastix/downsampled_data/AL207_fine_25um_points.txt')\n",
    "compute_transformation_wo_registration(r'/data/Lucas/Elastix/AL210', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al210_25um.tif', r'/data/Lucas/Elastix/downsampled_data/AL210_fine_25um_points.txt')\n",
    "compute_transformation(r'/data/Lucas/Elastix/AL215', r'/home/lucasdelez/Documents/AllenBrainCCFv3/Al215_25um.tif', r'/data/Lucas/Elastix/downsampled_data/AL215_fine_25um_points.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c086207-7e7d-460c-8d24-5c6d5221459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformix done !\n"
     ]
    }
   ],
   "source": [
    "#mouse='AL213'\n",
    "#compute_transformation(f'/data/Lucas/Elastix/{mouse}', f'/home/lucasdelez/Documents/AllenBrainCCFv3/{mouse}_25um.tif', f'/data/Lucas/Elastix/downsampled_data/{mouse}_fine_25um_points.txt')\n",
    "mouse='AL257'\n",
    "compute_transformation_wo_registration(f'/data/Lucas/Elastix/{mouse}', f'/home/lucasdelez/Documents/AllenBrainCCFv3/{mouse}_25um.tif', f'/data/Lucas/Elastix/downsampled_data/{mouse}_fine_25um_points.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f1dc2-2bf8-4a9b-87dc-7278ff5d9414",
   "metadata": {},
   "source": [
    "### 3.3 Extract and correct atlas coordinates ???\n",
    "\n",
    "I can't test this part yet.\n",
    "\n",
    "It is necessary to downsample our brain to 25um x 25um x 25um in order to match the Allen atlas.\n",
    "Registration is performed via Elastix and Transformix (alignment btw atlas brain and our brains).\n",
    "\n",
    "**get_pt_natlas** reads (.txt) files from precedent part and eliminates negative values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc4606-b4b3-4d8f-880f-74fbfcea7d12",
   "metadata": {},
   "source": [
    "#### >\n",
    "\n",
    "Relabel some regions of the atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c93ee1-e57c-4e72-ac91-24fc388c55e9",
   "metadata": {},
   "source": [
    "## 4. Plots and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4615562-4fcb-4472-b403-284c20da59a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_with_counts= region_counts (points_in_atlas)\n",
    "sorted_pd=sort_by_parent(region_with_counts,out_name)\n",
    "plot_hist(sorted_pd,'AL211')#plot as histogram and save as .html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba2cba-79f8-486b-838b-6c4d3f6aa543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_df(df):\n",
    "    ''' group data frame items by parent id structure\n",
    "    '''\n",
    "    grouped_pd=df.groupby(['parent_structure_id'],as_index=False).sum()\n",
    "    d= {'id': grouped_pd.parent_structure_id.astype(int), 'Total_counts': grouped_pd.Total_counts}\n",
    "    grouped_pd2= pd.DataFrame(data=d)\n",
    "    result = pd.merge(grouped_pd2, na.atlas_labels, on=[\"id\"])\n",
    "    result.sort_values(['Total_counts'], ascending=True, inplace=True)\n",
    "    # result is the final pd\n",
    "    return result\n",
    "\n",
    "# group item based on parents and save as excel\n",
    "result= parent_df(sorted_pd)\n",
    "result.to_excel(f'{out_name}_parent.xls')  Legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced1836-b0d4-4ab3-9536-76061376dfc3",
   "metadata": {},
   "source": [
    "## 5. Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a8ae2a-6360-44a7-aa6c-3234e32d19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = fdialog.askdirectory(initialdir=os.path.realpath(\"__file__\"), title='Please select the directory containing segmentation image sequences')\n",
    "output_folder = fdialog.askdirectory(initialdir=os.path.realpath(\"__file__\"), title='Please select the output directory')\n",
    "\n",
    "downsampling_factor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c4345-50d2-4ff5-a624-d8a25fd31dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_imgs(in_folder, out_folder, factor):\n",
    "    images=os.listdir(in_folder)\n",
    "    images=[i for i in images if i.endswith('.tif')]\n",
    "    images.sort()\n",
    "    \n",
    "    for count,item in enumerate(tqdm(images)):\n",
    "        if count > -1: #so you don't have to start from beginning if problem\n",
    "            img = cv2.imread(in_folder + \"/\" + item, -1)\n",
    "            out_img = block_reduce(img, block_size=(factor, factor), func=np.mean)\n",
    "            out_img = Image.fromarray(out_img)\n",
    "            out_img.save(out_folder + \"//\" + \"ds_\" + os.path.basename(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2a3ab-0d1e-4bc1-8e23-38f899f181e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_imgs(input_folder, output_folder, downsampling_factor) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
