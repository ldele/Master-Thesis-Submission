{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315b1c67-490d-434f-8394-86ba65aec0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data_analysis env\n",
    "\n",
    "import os\n",
    "import tkinter.filedialog as fdialog #window to select directories\n",
    "from tqdm import tqdm #progress bars\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "#import anne_code.Neuron_analysis as na #custum functions\n",
    "#from anne_code.Neuron_analysis import *\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import SimpleITK as sitk #elastix\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "import warnings\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import dask_image.imread\n",
    "import random\n",
    "\n",
    "from skelly_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7738bc-ab6d-44c9-a94b-2697dffc98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e985c69d-d8c8-4fcd-9a8b-97220a604aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_al215_20220329_1_path = '/data/Lucas/AL215/seg-Al215_20220329_1'\n",
    "seg_al215_20220330_1_path = '/data/Lucas/AL215/seg-Al215_20220330_1'\n",
    "seg_al215_default_path = '/data/Lucas/AL215/seg-Al215_default'\n",
    "seg_al215_default_dense_path = '/data/Lucas/AL215/seg-Al215_default_dense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbdefb9-141d-4fca-af8b-aa81aede91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_al215_20220329_1 = dask_image.imread.imread(seg_al215_20220329_1_path + '/*.tif')\n",
    "seg_al215_20220330_1 = dask_image.imread.imread(seg_al215_20220330_1_path + '/*.tif')\n",
    "seg_al215_default = dask_image.imread.imread(seg_al215_default_path + '/*.tif')\n",
    "seg_al215_default_dense = dask_image.imread.imread(seg_al215_default_dense_path + '/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "501e5a94-2694-4fb4-a481-4575526fc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_s, m1, m2, diff_n = [], [], [], []\n",
    "n_pixels = seg_al215_20220329_1.shape[1]*seg_al215_20220329_1.shape[2]\n",
    "for _ in range(40):\n",
    "    r_i = random.randint(0,seg_al215_20220329_1.shape[0])\n",
    "    img1 = seg_al215_20220329_1[r_i].compute()\n",
    "    img2 = seg_al215_20220330_1[r_i].compute()\n",
    "    m1.append(np.mean(img1[img1>0]))\n",
    "    m2.append(np.mean(img2[img2>0]))\n",
    "    diff_img = np.abs(img1-img2)\n",
    "    diff_s.append(np.mean(diff_img))\n",
    "    diff_n.append((len(img1[img1>0])-len(img2[img2>0]))/n_pixels)\n",
    "    \n",
    "print(\"Mean difference between two stacks (value):\", np.mean(diff_s))\n",
    "print(\"Mean difference between two stacks (%non-zero pixels):\", np.mean(diff_n)*100)\n",
    "print(\"Mean pixel value of img1 (non-zero):\", np.mean(m1))\n",
    "print(\"Mean pixel value of img2 (non-zero):\", np.mean(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e935a17-1626-4ed8-bcc5-2c440fd3da8a",
   "metadata": {},
   "source": [
    "**Reload kernel before next**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92afe0c5-57f7-44bf-9390-d85cc0a884ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 s, sys: 54.9 s, total: 1min 32s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def binarize_stack(dask_stack):\n",
    "    #seg1 = dask_stack.astype('float32')\n",
    "    dask_stack[dask_stack>= 0.3] = 1\n",
    "    dask_stack[dask_stack< 0.3] = 0\n",
    "    return dask_stack.astype('uint8').compute()\n",
    "    \n",
    "bin_s = binarize_stack(seg_al215_20220329_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7f6c9d-3092-455a-a046-da47c96ffcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 2048, 2048)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c780c564-3d71-4682-afcb-dfcf8fea137e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 2048, 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d3db10-08c3-4c37-9681-2d43052ea0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe1bc40-1b3a-4f12-bb6e-3ab7f66d678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.2 s, sys: 25.7 s, total: 1min 1s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_files=get_dir(seg_al215_20220330_1_path)\n",
    "img_stack = [None]*len(list_files)\n",
    "for count, item in enumerate(list_files):\n",
    "    img = cv2.imread(item, cv2.COLOR_BGR2GRAY)\n",
    "    img[img >= 0.3] = 1\n",
    "    img[img < 0.3] = 0\n",
    "    img_stack[count] = img\n",
    "    \n",
    "img_stack = np.array(img_stack, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689bd024-6857-4dbe-9c12-d35c8ac3ab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seg-1000_AL215_rLS.tif'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0dcde0-13bd-4784-b4dc-6af21cb4f701",
   "metadata": {},
   "source": [
    "**New skeleton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4e04b0-63b5-483e-a503-1caa27a8fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeletons_3d_sep(input_folder, output_folder_loc):\n",
    "    \n",
    "    skel_count = 0\n",
    "    folder_list = []\n",
    "    thresh_list = 0.1*np.array(range(2,10,1))\n",
    "            \n",
    "    output_name = \"skel-\" + os.path.basename(input_folder)\n",
    "    output_dir = os.path.dirname(output_folder_loc)\n",
    "    output_folder = os.path.join(output_dir, output_name)\n",
    "    if os.path.exists(output_folder):\n",
    "        print(output_folder + \" already exists. Will be overwritten.\")\n",
    "        shutil.rmtree(output_folder)\n",
    "    os.makedirs(output_folder) \n",
    "    \n",
    "    for thresh in thresh_list:\n",
    "        dask_stack = dask_image.imread.imread(input_folder + \"/*.tif\")\n",
    "        dask_stack[dask_stack>=thresh] = 1\n",
    "        dask_stack[dask_stack<thresh] = 0\n",
    "        img_stack = dask_stack.astype('uint8').compute()\n",
    "        img_stack = morphology.skeletonize_3d(img_stack) # max output from skeletonize is 255 (0->255), uint8 data type\n",
    "        print(\"Skeleton for threshold\", thresh, \"computed !\")\n",
    "        folder_save = output_folder + '/skel_thresh_' + str(skel_count)\n",
    "        if not os.path.exists(folder_save):\n",
    "            os.makedirs(folder_save)\n",
    "            print(folder_save, \"directory created !\")\n",
    "        for count in range(dask_stack.shape[0]):\n",
    "            pil_image = Image.fromarray(img_stack[count])\n",
    "            pil_image.save(folder_save + '/' + os.path.basename(\"skeleton_image_\" + str(count) + \".tif\"))\n",
    "        print(\"Images for threshold\", thresh, \"saved !\")\n",
    "        skel_count += 1\n",
    "        folder_list.append(folder_save)\n",
    "        \n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443f62a2-fe72-477a-af36-ac47f8e2cb57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton for threshold 0.2 computed !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.30000000000000004 computed !\n",
      "Images for threshold 0.30000000000000004 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL215/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6 computed !\n",
      "/data/Lucas/AL215/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6 saved !\n",
      "Skeleton for threshold 0.7 computed !\n",
      "/data/Lucas/AL215/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7 saved !\n",
      "Skeleton for threshold 0.7999999999999999 computed !\n",
      "/data/Lucas/AL215/skel_thresh_6 directory created !\n",
      "Images for threshold 0.7999999999999999 saved !\n",
      "Skeleton for threshold 0.8999999999999999 computed !\n",
      "/data/Lucas/AL215/skel_thresh_7 directory created !\n",
      "Images for threshold 0.8999999999999999 saved !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/data/Lucas/AL215/skel_thresh_0',\n",
       " '/data/Lucas/AL215/skel_thresh_1',\n",
       " '/data/Lucas/AL215/skel_thresh_2',\n",
       " '/data/Lucas/AL215/skel_thresh_3',\n",
       " '/data/Lucas/AL215/skel_thresh_4',\n",
       " '/data/Lucas/AL215/skel_thresh_5',\n",
       " '/data/Lucas/AL215/skel_thresh_6',\n",
       " '/data/Lucas/AL215/skel_thresh_7']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeletons_3d_dask(seg_al215_20220330_1_path, \"/data/Lucas/AL215\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6915310c-136e-4a00-88f3-35482d0e31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((100,200,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861fe25b-0942-43c5-aef6-6f63be6ba9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 200, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2160955-b7ff-49cc-b745-0544e025585a",
   "metadata": {},
   "source": [
    "**Check skeletons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd12f87-28d8-460f-8d3b-bad0eb5d7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel0 = dask_image.imread.imread(r'/data/Lucas/AL215/skel_thresh_0/*.tif')\n",
    "skel3 = dask_image.imread.imread(r'/data/Lucas/AL215/skel_thresh_3/*.tif')\n",
    "skel5 = dask_image.imread.imread(r'/data/Lucas/AL215/skel_thresh_5/*.tif')\n",
    "skel7 = dask_image.imread.imread(r'/data/Lucas/AL215/skel_thresh_7/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0333739-71c8-44d0-b9e8-6116c987e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011911411509959464"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(skel0.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fde8cde9-1368-456a-9779-f90a84d573a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00099400845935364"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(skel3.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3ce97c2-92f6-40fa-8b41-45b576bcb127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008979517366186147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(skel5.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c297a3ed-0ca9-4283-a3f7-10f82063325e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007705351637951849"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(skel7.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3f4da-71b3-4b21-9b78-84d519431df2",
   "metadata": {},
   "source": [
    "**Weighted sum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cdf4920-b04e-4783-a031-05931b7c72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files=get_dir(r'/data/Lucas/AL215/skel_thresh_0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c46dc8c1-fc1f-4e02-9f18-3310b5d3a46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 ms, sys: 153 µs, total: 21.6 ms\n",
      "Wall time: 21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img1 = skel0[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ee797ff-476f-4c1a-b9c7-37bb7367d8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 ms, sys: 229 µs, total: 14.4 ms\n",
      "Wall time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img2 = cv2.imread(list_files[0], cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "430cfcc3-a00b-49a2-95ee-5a295e13469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = ['/data/Lucas/AL215/skel_thresh_0',\n",
    " '/data/Lucas/AL215/skel_thresh_1',\n",
    " '/data/Lucas/AL215/skel_thresh_2',\n",
    " '/data/Lucas/AL215/skel_thresh_3',\n",
    " '/data/Lucas/AL215/skel_thresh_4',\n",
    " '/data/Lucas/AL215/skel_thresh_5',\n",
    " '/data/Lucas/AL215/skel_thresh_6',\n",
    " '/data/Lucas/AL215/skel_thresh_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c621d5a9-ba70-49b4-8f20-c72c5d776e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files=get_dir(folder_list[0])\n",
    "thresh_list = 0.1*np.array(range(2,10,1))\n",
    "img_f = np.multiply(thresh_list[0],cv2.imread(folder + \"/\" + os.path.basename(list_files[0]), cv2.COLOR_BGR2GRAY))\n",
    "folder_save = r'/data/Lucas/AL215/'\n",
    "for count, folder in enumerate(folder_list[1:]):\n",
    "    img_f = np.add(img_f, np.multiply(thresh_list[count+1],cv2.imread(folder + \"/\" + os.path.basename(list_files[0]), cv2.COLOR_BGR2GRAY)))\n",
    "    pil_img = Image.fromarray(img_f)\n",
    "    pil_img.save(folder_save + '/def-' + os.path.basename(list_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4747d8-3a46-4cff-a8bd-673e1a538fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeletons_3d(input_folder, output_folder_loc):\n",
    "    \n",
    "    skel_count = 0\n",
    "    folder_list = []\n",
    "    thresh_list = 0.1*np.array(range(2,10,1))\n",
    "            \n",
    "    output_name = \"skel-\" + os.path.basename(input_folder)\n",
    "    output_folder = os.path.join(output_folder_loc, output_name)\n",
    "    if os.path.exists(output_folder):\n",
    "        print(output_folder + \" already exists. Will be overwritten.\")\n",
    "        shutil.rmtree(output_folder)\n",
    "    os.makedirs(output_folder) \n",
    "    \n",
    "    for thresh in thresh_list:\n",
    "        dask_stack = dask_image.imread.imread(input_folder + \"/*.tif\")\n",
    "        dask_stack[dask_stack>=thresh] = 1\n",
    "        dask_stack[dask_stack<thresh] = 0\n",
    "        img_stack = dask_stack.astype('uint8').compute()\n",
    "        img_stack = morphology.skeletonize_3d(img_stack) # max output from skeletonize is 255 (0->255), uint8 data type\n",
    "        print(\"Skeleton for threshold\", thresh, \"computed !\")\n",
    "        folder_save = output_folder + '/skel_thresh_' + str(skel_count)\n",
    "        if not os.path.exists(folder_save):\n",
    "            os.makedirs(folder_save)\n",
    "            print(folder_save, \"directory created !\")\n",
    "        for count in range(dask_stack.shape[0]):\n",
    "            pil_image = Image.fromarray(img_stack[count])\n",
    "            pil_image.save(folder_save + '/' + os.path.basename(\"skeleton_image_\" + str(count + 100000) + \".tif\"))\n",
    "        print(\"Images for threshold\", thresh, \"saved !\")\n",
    "        skel_count += 1\n",
    "        folder_list.append(folder_save)\n",
    "        \n",
    "    list_files=get_dir(folder_list[0])\n",
    "    folder_save = output_folder + \"/weighted_sum_skeleton\"\n",
    "    if not os.path.exists(folder_save):\n",
    "        os.makedirs(folder_save)\n",
    "        print(folder_save, \"directory created !\")\n",
    "    for i in range(tqdm(len(list_files))):\n",
    "        img_f = np.multiply(thresh_list[0],cv2.imread(folder_list[0] + \"/\" + os.path.basename(list_files[i]), cv2.COLOR_BGR2GRAY))\n",
    "        for count, folder in enumerate(folder_list[1:]):\n",
    "            img_f = np.add(img_f, np.multiply(thresh_list[count+1],cv2.imread(folder + \"/\" + os.path.basename(list_files[i]), cv2.COLOR_BGR2GRAY)))\n",
    "            pil_img = Image.fromarray(img_f)\n",
    "            pil_img.save(folder_save + '/def-' + os.path.basename(list_files[i]))\n",
    "        \n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b607392-6925-4da2-b81b-e1acf98ec8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton for threshold 0.2 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_0 directory created !\n",
      "Images for threshold 0.2 saved !\n",
      "Skeleton for threshold 0.30000000000000004 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_1 directory created !\n",
      "Images for threshold 0.30000000000000004 saved !\n",
      "Skeleton for threshold 0.4 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_2 directory created !\n",
      "Images for threshold 0.4 saved !\n",
      "Skeleton for threshold 0.5 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_3 directory created !\n",
      "Images for threshold 0.5 saved !\n",
      "Skeleton for threshold 0.6000000000000001 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_4 directory created !\n",
      "Images for threshold 0.6000000000000001 saved !\n",
      "Skeleton for threshold 0.7000000000000001 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_5 directory created !\n",
      "Images for threshold 0.7000000000000001 saved !\n",
      "Skeleton for threshold 0.8 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_6 directory created !\n",
      "Images for threshold 0.8 saved !\n",
      "Skeleton for threshold 0.9 computed !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_7 directory created !\n",
      "Images for threshold 0.9 saved !\n",
      "/data/Lucas/AL207/skel-seg-Al207_20220329_1/weighted_sum_skeleton directory created !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_0',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_1',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_2',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_3',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_4',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_5',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_6',\n",
       " '/data/Lucas/AL207/skel-seg-Al207_20220329_1/skel_thresh_7']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeletons_3d('/data/Lucas/AL207/seg-Al207_20220329_1', \"/data/Lucas/AL207\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9146ecd9-9f45-4d5d-bbd2-669832172512",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bea2cb7f-06d8-4470-8b0a-08eed67825af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skelly_module import *\n",
    "\n",
    "def weighted_sum_skeleton(folder_list, thresh_list, output_folder):\n",
    "    if len(folder_list) != len(thresh_list):\n",
    "        print('Error ! Input of different sizes.)')\n",
    "        return\n",
    "    list_files=get_dir(folder_list[0])\n",
    "    folder_save = output_folder + \"/weighted_sum_skeleton\"\n",
    "    if not os.path.exists(folder_save):\n",
    "        os.makedirs(folder_save)\n",
    "        print(folder_save, \"directory created !\")\n",
    "    for i in range(len(list_files)):\n",
    "        img_f = np.multiply(thresh_list[0],cv2.imread(folder_list[0] + \"/\" + os.path.basename(list_files[i]), cv2.COLOR_BGR2GRAY))\n",
    "        for count, folder in enumerate(folder_list[1:]):\n",
    "            img_f = np.add(img_f, np.multiply(thresh_list[count+1],cv2.imread(folder + \"/\" + os.path.basename(list_files[i]), cv2.COLOR_BGR2GRAY)))\n",
    "            pil_img = Image.fromarray(img_f)\n",
    "            pil_img.save(folder_save + '/def-' + os.path.basename(list_files[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df397b4b-398f-4bea-bf4a-eb200d3a4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = ['/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_0',\n",
    " '/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_1',\n",
    " '/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_2',\n",
    " '/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_3',\n",
    " '/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_4',\n",
    " '/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_5',\n",
    " '/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_6',\n",
    " '/data/Lucas/AL207/skel-seg-Al207-substack/skel_thresh_7']\n",
    "\n",
    "thresh_list = 0.1*np.array(range(2,10,1))\n",
    "output_folder = r'/data/Lucas/AL207/skel-seg-Al207-substack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd803d88-bed1-451d-88a8-3a140d257463",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sum_skeleton(folder_list, thresh_list, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2b7c8-cd13-460e-809b-165d343ec65d",
   "metadata": {},
   "source": [
    "### Better skeleton testing\n",
    "\n",
    "Might not have time to implement <br/>\n",
    "missing ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd9142c-3189-4122-94c2-06b3deb1a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f65433-e47d-4831-82b2-a3e77d68ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   the following subiteration functions are how each image is rotated to the next direction for removing\n",
    "   boundary voxels in the order described in the reference paper\n",
    "   us, ne, wd,..\n",
    "   \n",
    "    reference paper\n",
    "   http://web.inf.u-szeged.hu/ipcg/publications/papers/PalagyiKuba_GMIP1999.pdf\n",
    "   input should be a binary image/ already segmented\n",
    "\"\"\"\n",
    "from rotationalOperators.rotational_operators import get_directions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b07bb15-b793-4207-af29-67df0ac3fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions_list = get_directions_list(np.zeros((3,3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bd64be2-68f6-48b4-ae2f-623b5185fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   array that has calculated the validity of the 14 templates beforehand and stored each index which is\n",
    "   decimal number of the binary string of 26 values (sqrt(3) connectivity) that are around a single voxel \n",
    "\"\"\"\n",
    "lookUpTablearray = np.load('rotationalOperators/lookupTablearray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275109ce-b33a-4887-a38a-9ff0c7bbd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convolveImage(arr, flippedKernel):\n",
    "    arr = np.ascontiguousarray(arr, dtype=np.uint64)\n",
    "    result = convolve(arr, flippedKernel, mode='constant', cval=0)\n",
    "    result[arr == 0] = 0\n",
    "    return result\n",
    "\n",
    "sElement = ndimage.generate_binary_structure(3, 1)\n",
    "\n",
    "def _getBouondariesOfimage(image):\n",
    "    \"\"\"\n",
    "       function to find boundaries/border/edges of the array/image\n",
    "    \"\"\"\n",
    "\n",
    "    erode_im = ndimage.morphology.binary_erosion(image, sElement)\n",
    "    boundaryIm = image - erode_im\n",
    "    return boundaryIm\n",
    "\n",
    "def _skeletonPass(image):\n",
    "    \"\"\"\n",
    "        each pass consists of 12 serial subiterations and finding the\n",
    "        boundaries of the padded image/array\n",
    "    \"\"\"\n",
    "    boundaryIm = _getBouondariesOfimage(image)\n",
    "    numPixelsremovedList = [] * 12\n",
    "    boundaryIndices = list(set(map(tuple, list(np.transpose(np.nonzero(boundaryIm))))))\n",
    "    directionList = get_directions_list(image)\n",
    "    for i in range(len(directionList)):\n",
    "        convImage = _convolveImage(image, directionList[i])\n",
    "        totalPixels, image = _applySubiter(image, boundaryIndices, convImage)\n",
    "        print(\"number of pixels removed in the {} direction is {}\". format(i, totalPixels))\n",
    "        numPixelsremovedList.append(totalPixels)\n",
    "    numPixelsremoved = sum(numPixelsremovedList)\n",
    "    return numPixelsremoved, image\n",
    "\n",
    "\n",
    "def _applySubiter(image, boundaryIndices, convImage):\n",
    "    \"\"\"\n",
    "       each subiteration paralleley reduces the border voxels in 12 directions\n",
    "       going through each voxel and marking if it can be deleted or not in a\n",
    "       different image named temp_del and finally multiply it with the original\n",
    "       image to delete the voxels so marked\n",
    "    \"\"\"\n",
    "    temp_del = np.zeros_like(image)\n",
    "    # boundaryIndicesCopy = copy.deepcopy(boundaryIndices)\n",
    "    lenB = len(boundaryIndices)\n",
    "    for k in range(0, lenB):\n",
    "        temp_del[boundaryIndices[k]] = lookUpTablearray[convImage[boundaryIndices[k]]]\n",
    "    numpixel_removed = np.einsum('ijk->', image * temp_del, dtype=int)\n",
    "    image[temp_del == 1] = 0\n",
    "    return numpixel_removed, image\n",
    "\n",
    "\n",
    "def getSkeletonize3D(image):\n",
    "    \"\"\"\n",
    "    function to skeletonize a 3D binary image with object in brighter contrast than background.\n",
    "    In other words, 1 = object, 0 = background\n",
    "    \"\"\"\n",
    "    assert np.max(image) in [0, 1]\n",
    "    zOrig, yOrig, xOrig = np.shape(image)\n",
    "    padImage = np.lib.pad(image, 1, 'constant', constant_values=0)\n",
    "    start_skeleton = time.time()\n",
    "    pass_no = 0\n",
    "    numpixel_removed = 0\n",
    "    while pass_no == 0 or numpixel_removed > 0:\n",
    "        numpixel_removed, padImage = _skeletonPass(padImage)\n",
    "        print(\"number of pixels removed in pass {} is {}\".format(pass_no, numpixel_removed))\n",
    "        pass_no += 1\n",
    "    print(\"done %i number of pixels in %f seconds\" % (np.sum(image), time.time() - start_skeleton))\n",
    "    return padImage[1: zOrig + 1, 1: yOrig + 1, 1: xOrig + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "882226e2-10c4-44d1-90d2-803d3a9f8230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pixels removed in the 0 direction is 0\n",
      "number of pixels removed in the 1 direction is 0\n",
      "number of pixels removed in the 2 direction is 0\n",
      "number of pixels removed in the 3 direction is 0\n",
      "number of pixels removed in the 4 direction is 0\n",
      "number of pixels removed in the 5 direction is 0\n",
      "number of pixels removed in the 6 direction is 0\n",
      "number of pixels removed in the 7 direction is 0\n",
      "number of pixels removed in the 8 direction is 0\n",
      "number of pixels removed in the 9 direction is 0\n",
      "number of pixels removed in the 10 direction is 0\n",
      "number of pixels removed in the 11 direction is 0\n",
      "number of pixels removed in pass 0 is 0\n",
      "done 150 number of pixels in 0.031449 seconds\n"
     ]
    }
   ],
   "source": [
    "sample = np.ones((5, 5, 6), dtype=np.uint8)\n",
    "resultSkel = getSkeletonize3D(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbde1f60-6104-4b10-88cb-c431b55be23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultSkel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2154763-97f0-4ac3-b5a0-cfdc214d2161",
   "metadata": {},
   "source": [
    "### Small skeletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d158822-9e69-4931-ae71-c1245ceed433",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a61a9-ecdd-4368-8c05-efae8a5bbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cc3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162cdfd-1692-4269-9922-c169147b7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "def set_to_zero(np.ndarray[float, ndim=3] vol, np.ndarray[long long, ndim=2] list_coords):\n",
    "    cdef int i = 0\n",
    "    for i in range(len(list_coords)):\n",
    "        vol[list_coords[i][0],list_coords[i][1],list_coords[i][2]] = 0\n",
    "    \n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d8f3a-4908-433e-bd4a-c8e9ba077c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_skeletons_3d(img_stack):\n",
    "    \n",
    "    thresh_list = 0.1*np.array(range(2,10,1))\n",
    "    skel_stack = np.zeros(img_stack.shape, dtype=np.float32)\n",
    "    \n",
    "    for thresh in thresh_list:\n",
    "        binary_stack = np.copy(img_stack.view(dtype=np.float32)) #forces a copy, actually segmentation output is already float32 from TrailMap\n",
    "        binary_stack[binary_stack>=thresh] = 1\n",
    "        binary_stack[binary_stack<thresh] = 0\n",
    "        binary_stack = morphology.skeletonize_3d(binary_stack)\n",
    "        skel_stack = np.add(skel_stack, np.multiply(binary_stack, thresh, dtype=np.float32), dtype=np.float32)\n",
    "        print(\"Skeleton for threshold\", thresh, \"computed !\")\n",
    "        \n",
    "    return skel_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d977ee-deb7-41c5-a5a3-67d36e73184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_stack = from_folder_to_stack(r'/data/Lucas/Substacks/AL215s/seg-Al215-substack-20220505-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b347fa1-d6ea-4e6b-a83f-d94e57afcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_small_elements(stack, size_threshold):\n",
    "    #Removing small elements increases the mean probability of remaining pixels.\n",
    "    #(Small elements are associated with lower probabilities of axon presence)\n",
    "    \n",
    "    label_stack = np.copy(stack.view(dtype=np.float32)) # force a copy\n",
    "    label_stack[label_stack > 0] = 1\n",
    "    label_stack = measure.label(label_stack, background=0) #computationally expensive\n",
    "    print('Start: individual \"blobs\":', np.max(label_stack))\n",
    "    \n",
    "    propsa = measure.regionprops(label_stack)\n",
    "    del label_stack #liberate memory\n",
    "    \n",
    "    index_list = []\n",
    "    for count, item in enumerate(propsa):\n",
    "        if len(item.coords) < size_threshold:\n",
    "            index_list.append(count)\n",
    "            \n",
    "    print('Blobs that are removed:', len(index_list))\n",
    "    \n",
    "    stack_ = np.copy(stack)\n",
    "    for i in range(len(index_list)):\n",
    "        stack_ = set_to_zero(stack_, propsa[index_list[i]].coords)\n",
    "                \n",
    "    return stack_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4622c2-28e4-4188-bb15-b6290d23dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "skel_stack = small_skeletons_3d(img_stack)\n",
    "skel_stack[skel_stack > 0] = 1\n",
    "skel_stack = skel_stack.view(dtype=np.uint32)\n",
    "trimmed_skel_stack = cc3d.dust(skel_stack,threshold=100, in_place=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a54558-f8b8-415e-8201-4d087d84c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_test = trimmed_skel_stack[trimmed_skel_stack!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7070ae-0838-4d26-9e0d-69786b1759eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_stack = small_skeletons_3d(img_stack)\n",
    "trimmed_skel_stack = trim_small_elements(skel_stack, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545238f-45cd-4a32-a429-e4a7c12c865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_test_2 = trimmed_skel_stack[trimmed_skel_stack!=0]\n",
    "len(trim_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b55363-aa3b-4c93-9ebf-cd656568740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_vol_to_folder(skel_stack, r'Al207s-dense.tif', r'/data/Lucas/Substacks/AL207s/seg_substacks/skel-Al207s-dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb09b28-4ad1-4af8-ae14-a665632af77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_densities = compute_skel_probas(skel_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3513c12-2574-4bc5-8e0c-823b2cad83da",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_densities_trimmed = compute_skel_probas(trimmed_skel_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c9ef3-83d8-4457-a8b9-eead18fc5db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
